{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8148862,"sourceType":"datasetVersion","datasetId":4819198},{"sourceId":8149701,"sourceType":"datasetVersion","datasetId":4819808}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.metrics import classification_report\nimport joblib\nimport numpy as np\nfrom nltk.tokenize import word_tokenize\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:02:46.058679Z","iopub.execute_input":"2024-04-18T16:02:46.059299Z","iopub.status.idle":"2024-04-18T16:02:50.034370Z","shell.execute_reply.started":"2024-04-18T16:02:46.059266Z","shell.execute_reply":"2024-04-18T16:02:50.032882Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\ndata = pd.read_csv(\"/content/drive/MyDrive/LUT/ISS/fakenewscorpus/preprocessed_data.csv\")\n\n# Splitting into X (features) and y (target)\nX = data['content']\ny = data['label']","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:02:50.037112Z","iopub.execute_input":"2024-04-18T16:02:50.037911Z","iopub.status.idle":"2024-04-18T16:03:57.701618Z","shell.execute_reply.started":"2024-04-18T16:02:50.037863Z","shell.execute_reply":"2024-04-18T16:03:57.700596Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Data Splitting to Train, Validation and Test\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:03:57.703801Z","iopub.execute_input":"2024-04-18T16:03:57.705284Z","iopub.status.idle":"2024-04-18T16:03:57.864166Z","shell.execute_reply.started":"2024-04-18T16:03:57.705237Z","shell.execute_reply":"2024-04-18T16:03:57.862687Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# TF-IDF Vectorization\ndef custom_tokenizer(text):\n    # convert to lowercase, remove punctuation and numeric data, then tokenize\n    text = text.lower()\n    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n    tokens = word_tokenize(text)\n    return tokens\n\n\nvectorizer = TfidfVectorizer(tokenizer=custom_tokenizer, max_features=3000, norm=\"l2\")\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\njoblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T16:03:57.866128Z","iopub.execute_input":"2024-04-18T16:03:57.866507Z","iopub.status.idle":"2024-04-18T16:46:43.095653Z","shell.execute_reply.started":"2024-04-18T16:03:57.866478Z","shell.execute_reply":"2024-04-18T16:46:43.093839Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n  warnings.warn(\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"['tfidf_vectorizer.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"# Define MLPClassifier model\nmlp_classifier = MLPClassifier(hidden_layer_sizes=(512, 256, 128),\n                               activation='relu',\n                               alpha=0.001,  # L2 regularization parameter\n                               solver='adam',\n                               batch_size=32,\n                               learning_rate='adaptive',\n                               max_iter=10,\n                               random_state=42,\n                               early_stopping=True,  # Enable early stopping to prevent overfitting\n                               validation_fraction=0.1,  # Validation set size for early stopping\n                               n_iter_no_change=10,  # Number of epochs with no improvement to stop training\n                               verbose=True\n                               )\n\n# Train the MLPClassifier model\nmlp_classifier.fit(X_train_vec, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T17:40:01.351543Z","iopub.execute_input":"2024-04-18T17:40:01.352204Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Iteration 1, loss = 0.28891862\nValidation score: 0.894549\nIteration 2, loss = 0.25752290\nValidation score: 0.900491\nIteration 3, loss = 0.24597684\nValidation score: 0.897914\nIteration 4, loss = 0.23890883\nValidation score: 0.899717\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predictions with test data\ny_pred = mlp_classifier.predict(X_test_vec)\n\n# Calculate metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\n# Generate classification report\nclass_report = classification_report(y_test, y_pred)\nprint(class_report)\n\n# Visualize confusion matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nconf_matrix = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n\n# Save metrics in a text file\nwith open(\"MLP-Report.txt\", \"w\") as file:\n    file.write(\"Accuracy: {:.4f}\\n\".format(accuracy))\n    file.write(\"Precision: {:.4f}\\n\".format(precision))\n    file.write(\"Recall: {:.4f}\\n\".format(recall))\n    file.write(\"F1-score: {:.4f}\\n\".format(f1))\n    file.write(\"\\nClassification Report:\\n\")\n    file.write(class_report)\n    file.write(\"\\nConfusion Matrix:\\n\")\n    file.write(np.array2string(conf_matrix, separator=', '))\n\n# Save the trained model\njoblib.dump(mlp_classifier, 'mlp_model.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Validation with Cross-Domain LIAR Data","metadata":{}},{"cell_type":"code","source":"# Load the LIAR Cross-Domain Test data\ntest_df = pd.read_csv(\"/content/drive/MyDrive/LUT/ISS/cross-domain-data-liar/labeled-strictness-high-test.tsv\", sep='\\t', header=None)\n\n# Extract news (X) and labels (y) from the test data\nX = test_df[2]  # News Content in column 2\ny = test_df[14]  # Label in column 15\n\n# Load the Vectorizer\ndef custom_tokenizer(text):\n    # convert to lowercase, remove punctuation and numeric data, then tokenize\n    text = text.lower()\n    text = ''.join([char for char in text if char.isalpha() or char.isspace()])\n    tokens = word_tokenize(text)\n    return tokens\n\n\nvectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\nX_test_vec = vectorizer.fit_transform(X_test)\n\n# Load the trained model\nmlp_classifier = joblib.load('mlp_model.pkl')\n\n# Make predictions with the trained MLPClassifier model\ny_pred = mlp_classifier.predict(X_test_vec)\n\n# Calculate metrics\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\n# Generate classification report\nclass_report = classification_report(y_test, y_pred)\nprint(class_report)\n\n# Visualize confusion matrix\nconf_matrix = confusion_matrix(y_test, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n\n# Save metrics in a text file\nwith open(\"MLP-CrossDomain-Report\", \"w\") as file:\n    file.write(\"Accuracy: {:.4f}\\n\".format(accuracy))\n    file.write(\"Precision: {:.4f}\\n\".format(precision))\n    file.write(\"Recall: {:.4f}\\n\".format(recall))\n    file.write(\"F1-score: {:.4f}\\n\".format(f1))\n    file.write(\"\\nClassification Report:\\n\")\n    file.write(class_report)\n    file.write(\"\\nConfusion Matrix:\\n\")\n    file.write(np.array2string(conf_matrix, separator=', '))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}